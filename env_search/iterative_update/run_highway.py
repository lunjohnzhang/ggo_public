import os
import gin
import fire
import json
import multiprocessing
import numpy as np
import shutil

from itertools import repeat
from logdir import LogDir
from env_search.competition.module import single_simulation as competition_single_simulation
from env_search.warehouse.module import single_simulation as kiva_single_simulation
from env_search.utils import (
    kiva_env_str2number,
    competition_env_str2number,
    get_n_valid_vertices,
    load_pibt_default_config,
    single_sim_done,
)


def run_highway_single(
    logdir: LogDir,
    results_dir,
    domain_config,
    map_filepath,
    domain,
    seed,
):
    gin.parse_config_file(domain_config)

    # Read in map
    with open(map_filepath, "r") as f:
        raw_env_json = json.load(f)
    map_name = raw_env_json["name"]
    optimize_wait = raw_env_json[
        "optimize_wait"] if "optimize_wait" in raw_env_json else False
    num_agents = raw_env_json["piu_n_agent"]
    all_weights = raw_env_json["weights"]

    if domain == "kiva":
        map_np = kiva_env_str2number(raw_env_json["layout"])
    elif domain == "competition":
        map_np = competition_env_str2number(raw_env_json["layout"])

    n_valid_vertices = get_n_valid_vertices(map_np, domain)

    if domain == "competition":
        kwargs = {}
        if optimize_wait:
            wait_costs = all_weights[:n_valid_vertices]
            edge_weights = all_weights[n_valid_vertices:]
            kwargs = {
                "weights":
                    json.dumps(edge_weights),
                "wait_costs":
                    json.dumps(wait_costs),
                "map_json_path":
                    gin.query_parameter("CompetitionConfig.map_path"),
                "simulation_steps":
                    gin.query_parameter("CompetitionConfig.simulation_time"),
                # Defaults
                "gen_random":
                    True,
                "num_tasks":
                    100000,
                "plan_time_limit":
                    1,
                "preprocess_time_limit":
                    1800,
                "file_storage_path":
                    "large_files",
                "task_assignment_strategy":
                    "roundrobin",
                "num_tasks_reveal":
                    1,
                "config":
                    load_pibt_default_config(),  # Use PIBT default config
            }
        else:
            kwargs = {
                "weights":
                    json.dumps(all_weights),
                "map_json_path":
                    gin.query_parameter("CompetitionConfig.map_path"),
                "simulation_steps":
                    gin.query_parameter("CompetitionConfig.simulation_time"),
                # Defaults
                "gen_random":
                    True,
                "num_tasks":
                    100000,
                "plan_time_limit":
                    1,
                "preprocess_time_limit":
                    1800,
                "file_storage_path":
                    "large_files",
                "task_assignment_strategy":
                    "roundrobin",
                "num_tasks_reveal":
                    1,
                "config":
                    load_pibt_default_config(),  # Use PIBT default config
            }
        throughput = competition_single_simulation(seed, num_agents, kwargs,
                                                   results_dir)
    elif domain == "kiva":
        raise NotImplementedError()

    return throughput


def run_highway(
    logdir_path: str,
    domain_config,
    n_evals,
    n_workers,
    domain,
):
    """Run each individual highway generated by `gen_highway` script

    Args:
        logdir_path (str): path to logdir of highways generated
        domain_config (str): path to the algo config
        n_evals (int): number of simulations to run for each highway
        n_workers (int): number of workers
        domain (str): domain of the simulation
    """
    logdir = LogDir("run_highway", custom_dir=logdir_path)
    all_map_filepaths = []
    maps_dir = logdir.dir("maps")
    for map_file in os.listdir(maps_dir):
        all_map_filepaths.extend([os.path.join(maps_dir, map_file)] * n_evals)

    n_maps = len(list(os.listdir(maps_dir)))
    pool = multiprocessing.Pool(n_workers)
    seeds = np.arange(n_evals)
    results_dir = logdir.dir("results", touch=True)

    # Always check for finished runs
    all_seeds = np.tile(seeds, n_maps)
    maps_to_run = []
    seeds_to_run = []
    for map_filepath, seed in zip(all_map_filepaths, all_seeds):
        with open(map_filepath, "r") as f:
            raw_env_json = json.load(f)
        num_agents = raw_env_json["piu_n_agent"]
        sim_dir_full = os.path.join(results_dir,
                                    f"sim-agent_num={num_agents}-seed={seed}")
        if not single_sim_done(sim_dir_full):
            if os.path.isdir(sim_dir_full):
                shutil.rmtree(sim_dir_full)
            maps_to_run.append(map_filepath)
            seeds_to_run.append(seed)

    n_simulations = len(maps_to_run)
    if n_simulations > 0:
        pool.starmap(
            run_highway_single,
            zip(
                repeat(logdir, n_simulations),
                repeat(results_dir, n_simulations),
                repeat(domain_config, n_simulations),
                maps_to_run,
                repeat(domain, n_simulations),
                seeds_to_run,  # Repeat for n_maps times
            ),
        )
    else:
        print("All simulations are done")


if __name__ == "__main__":
    fire.Fire(run_highway)
